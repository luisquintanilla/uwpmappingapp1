// This file was auto-generated by ML.NET Model Builder. 

using System;
using System.Collections.Generic;
using System.IO;
using System.Linq;
using Microsoft.ML;
using Microsoft.ML.Data;
using UWPMappingApp1ML.Model;
using Microsoft.ML.Vision;
using System.Security.Cryptography.X509Certificates;
using System.Net;

namespace UWPMappingApp1ML.ConsoleApp
{
    public static class ModelBuilder
    {
        private static string PROJECT_DIRECTORY = Path.GetFullPath(Path.Combine(AppContext.BaseDirectory, ".. /../../"));
        private static string WORKSPACE_RELATIVE_PATH = Path.Combine(PROJECT_DIRECTORY, "workspace");
        private static string DATA_DIRECTORY = Path.Combine(PROJECT_DIRECTORY, @"../../../../../data/EuroSAT/");
        private static string TRAIN_DATA_FILEPATH = Path.Combine(PROJECT_DIRECTORY, DATA_DIRECTORY, "traindata_head.tsv");
        private static string MODEL_FILEPATH = @"../../../../UWPMappingApp1ML.Model/MLModel.zip";
        private static Random RANDOM = new Random(Seed: 1);

        // Create MLContext to be shared across the model creation workflow objects 
        // Set a random seed for repeatable/deterministic results across multiple trainings.
        private static MLContext mlContext = new MLContext(seed: 1);

        public static void CreateModel()
        {

            Console.WriteLine("AppContext.BaseDirectory: {0}", AppContext.BaseDirectory);
            Console.WriteLine("PROJECT_DIRECTORY: {0}", PROJECT_DIRECTORY);
            Console.WriteLine("WORKSPACE_RELATIVE_PATH: {0}", WORKSPACE_RELATIVE_PATH);
            Console.WriteLine("DATA_DIRECTORY: {0}", DATA_DIRECTORY);
            Console.WriteLine("TRAIN_DATA_FILEPATH: {0}", TRAIN_DATA_FILEPATH);

            Datasets data = LoadData(TRAIN_DATA_FILEPATH);

            IDataView trainingDataView = mlContext.Data.LoadFromEnumerable(data.TrainSet);
            IDataView testDataView = mlContext.Data.LoadFromEnumerable(data.TestSet);

            // Build training pipeline
            IEstimator<ITransformer> trainingPipeline = BuildTrainingPipeline(mlContext);

            // Train Model
            ITransformer mlModel = TrainModel(mlContext, trainingDataView, trainingPipeline);

            // Evaluate quality of Model
            Evaluate(mlContext, testDataView, mlModel);

            // Save model
            SaveModel(mlContext, mlModel, MODEL_FILEPATH, trainingDataView.Schema);
        }

        static Datasets LoadData(string dataPath)
        {
            // Load the data from the file
            var datasets =
                File.ReadAllLines(TRAIN_DATA_FILEPATH) // Read File
                .Select(line =>
                {
                    var columns = line.Split('\t'); // Split data into columns
                    return new ModelInput { Label = columns[0], ImageSource = Path.Combine(DATA_DIRECTORY, columns[1]) };
                })
                //.OrderBy(x => RANDOM.Next())
                .GroupBy(image => image.Label) // Group by category/label
                .Select(category => // Create train/test set for each of the categories
                {
                    int count = category.Count();
                    int trainCount = (int)(count * .90); 
                    int testCount = (int)(count - trainCount);
                    return new Datasets { TrainSet = category.Take(trainCount), TestSet = category.Skip(trainCount).Take(testCount) };
                });

            // Flatten train/test category datasets and shuffle them
            IEnumerable<ModelInput> trainSet = datasets.SelectMany(category => category.TrainSet).OrderBy(_ => RANDOM.Next());
            IEnumerable<ModelInput> testSet = datasets.SelectMany(category => category.TestSet).OrderBy(_ => RANDOM.Next());

            return new Datasets
            {
                TrainSet = trainSet,
                TestSet = testSet
            };
        }

        public static IEstimator<ITransformer> BuildTrainingPipeline(MLContext mlContext)
        {
            // Data process configuration with pipeline data transformations 
            var dataProcessPipeline = mlContext.Transforms.Conversion.MapValueToKey("Label", "Label")
                                      .Append(mlContext.Transforms.LoadRawImageBytes("ImageSource_featurized", null, "ImageSource"))
                                      .Append(mlContext.Transforms.CopyColumns("Features", "ImageSource_featurized"));

            var classifierOptions = new ImageClassificationTrainer.Options()
            {
                LabelColumnName = "Label",
                FeatureColumnName = "Features",
                Epoch = 200,
                //WorkspacePath = WORKSPACE_RELATIVE_PATH,
                MetricsCallback = (metrics) => Console.WriteLine(metrics),
                EarlyStoppingCriteria = null,
                TestOnTrainSet = false
            };

            // Set the training algorithm 
                var trainer = mlContext.MulticlassClassification.Trainers.ImageClassification(classifierOptions)
                                      .Append(mlContext.Transforms.Conversion.MapKeyToValue("PredictedLabel", "PredictedLabel"));
            var trainingPipeline = dataProcessPipeline.Append(trainer);

            return trainingPipeline;
        }

        public static ITransformer TrainModel(MLContext mlContext, IDataView trainingDataView, IEstimator<ITransformer> trainingPipeline)
        {
            Console.WriteLine("=============== Training  model ===============");

            ITransformer model = trainingPipeline.Fit(trainingDataView);

            Console.WriteLine("=============== End of training process ===============");

            return model;
        }

        private static void Evaluate(MLContext mlContext, IDataView testDataView, ITransformer model)
        {
            // Evaluating model performance
            Console.WriteLine("=============== Calculating the model's accuracy metrics ===============");
            var evaluationResults = mlContext.MulticlassClassification.Evaluate(model.Transform(testDataView));
            PrintMulticlassClassificationMetrics(evaluationResults);
        }

        private static void SaveModel(MLContext mlContext, ITransformer mlModel, string modelRelativePath, DataViewSchema modelInputSchema)
        {
            // Save/persist the trained model to a .ZIP file
            Console.WriteLine($"=============== Saving the model  ===============");
            mlContext.Model.Save(mlModel, modelInputSchema, GetAbsolutePath(modelRelativePath));
            Console.WriteLine("The model is saved to {0}", GetAbsolutePath(modelRelativePath));
        }

        public static string GetAbsolutePath(string relativePath)
        {
            FileInfo _dataRoot = new FileInfo(typeof(Program).Assembly.Location);
            string assemblyFolderPath = _dataRoot.Directory.FullName;

            string fullPath = Path.Combine(assemblyFolderPath, relativePath);

            return fullPath;
        }

        public static void PrintMulticlassClassificationMetrics(MulticlassClassificationMetrics metrics)
        {
            Console.WriteLine($"************************************************************");
            Console.WriteLine($"*    Metrics for multi-class classification model   ");
            Console.WriteLine($"*-----------------------------------------------------------");
            Console.WriteLine($"    MacroAccuracy = {metrics.MacroAccuracy:0.####}, a value between 0 and 1, the closer to 1, the better");
            Console.WriteLine($"    MicroAccuracy = {metrics.MicroAccuracy:0.####}, a value between 0 and 1, the closer to 1, the better");
            Console.WriteLine($"    LogLoss = {metrics.LogLoss:0.####}, the closer to 0, the better");
            for (int i = 0; i < metrics.PerClassLogLoss.Count; i++)
            {
                Console.WriteLine($"    LogLoss for class {i + 1} = {metrics.PerClassLogLoss[i]:0.####}, the closer to 0, the better");
            }
            Console.WriteLine($"************************************************************");
        }

        public static void PrintMulticlassClassificationFoldsAverageMetrics(IEnumerable<TrainCatalogBase.CrossValidationResult<MulticlassClassificationMetrics>> crossValResults)
        {
            var metricsInMultipleFolds = crossValResults.Select(r => r.Metrics);

            var microAccuracyValues = metricsInMultipleFolds.Select(m => m.MicroAccuracy);
            var microAccuracyAverage = microAccuracyValues.Average();
            var microAccuraciesStdDeviation = CalculateStandardDeviation(microAccuracyValues);
            var microAccuraciesConfidenceInterval95 = CalculateConfidenceInterval95(microAccuracyValues);

            var macroAccuracyValues = metricsInMultipleFolds.Select(m => m.MacroAccuracy);
            var macroAccuracyAverage = macroAccuracyValues.Average();
            var macroAccuraciesStdDeviation = CalculateStandardDeviation(macroAccuracyValues);
            var macroAccuraciesConfidenceInterval95 = CalculateConfidenceInterval95(macroAccuracyValues);

            var logLossValues = metricsInMultipleFolds.Select(m => m.LogLoss);
            var logLossAverage = logLossValues.Average();
            var logLossStdDeviation = CalculateStandardDeviation(logLossValues);
            var logLossConfidenceInterval95 = CalculateConfidenceInterval95(logLossValues);

            var logLossReductionValues = metricsInMultipleFolds.Select(m => m.LogLossReduction);
            var logLossReductionAverage = logLossReductionValues.Average();
            var logLossReductionStdDeviation = CalculateStandardDeviation(logLossReductionValues);
            var logLossReductionConfidenceInterval95 = CalculateConfidenceInterval95(logLossReductionValues);

            Console.WriteLine($"*************************************************************************************************************");
            Console.WriteLine($"*       Metrics for Multi-class Classification model      ");
            Console.WriteLine($"*------------------------------------------------------------------------------------------------------------");
            Console.WriteLine($"*       Average MicroAccuracy:    {microAccuracyAverage:0.###}  - Standard deviation: ({microAccuraciesStdDeviation:#.###})  - Confidence Interval 95%: ({microAccuraciesConfidenceInterval95:#.###})");
            Console.WriteLine($"*       Average MacroAccuracy:    {macroAccuracyAverage:0.###}  - Standard deviation: ({macroAccuraciesStdDeviation:#.###})  - Confidence Interval 95%: ({macroAccuraciesConfidenceInterval95:#.###})");
            Console.WriteLine($"*       Average LogLoss:          {logLossAverage:#.###}  - Standard deviation: ({logLossStdDeviation:#.###})  - Confidence Interval 95%: ({logLossConfidenceInterval95:#.###})");
            Console.WriteLine($"*       Average LogLossReduction: {logLossReductionAverage:#.###}  - Standard deviation: ({logLossReductionStdDeviation:#.###})  - Confidence Interval 95%: ({logLossReductionConfidenceInterval95:#.###})");
            Console.WriteLine($"*************************************************************************************************************");

        }

        public static double CalculateStandardDeviation(IEnumerable<double> values)
        {
            double average = values.Average();
            double sumOfSquaresOfDifferences = values.Select(val => (val - average) * (val - average)).Sum();
            double standardDeviation = Math.Sqrt(sumOfSquaresOfDifferences / (values.Count() - 1));
            return standardDeviation;
        }

        public static double CalculateConfidenceInterval95(IEnumerable<double> values)
        {
            double confidenceInterval95 = 1.96 * CalculateStandardDeviation(values) / Math.Sqrt((values.Count() - 1));
            return confidenceInterval95;
        }
    }

    class Datasets
    {
        public IEnumerable<ModelInput> TrainSet { get; set; }
        public IEnumerable<ModelInput> TestSet { get; set; }

        //public IEnumerable<ModelInput> ValidationSet { get; set; }
    }

}
